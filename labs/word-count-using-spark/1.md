# <center>Word Count Using SPARK</center>

## Lab Overview

WordCount is a classic example in learning Spark, as Hello World in learning any programming language. This Learning Lab introduces how to use IDE in DLP to create a WordCount program and how to execute it to get the intended result. After completing this lab, the user is encouraged to try on their own for different variations of a data file. 

<font color='red'>Request access to the Data Learning Platform by sending a message to:</font> [datalearningplatform@cisco.com](mailto:datalearningplatform@cisco.com)

## Lab Objectives

* Learn how to get data from a file.
* Learn how to use some RDD operations on data.
* Learn how to write data to a new file with file creation in HDFS.


## Prerequisites

* Knowledge on Hadoop to store the data.
* Basic knowledge of how spark works.
* Use Chrome OS


## Step 1: Explore Data Learning Platform(DLP)

<font color='red'>Request access to the Data Learning Platform by sending a message to:</font> [datalearningplatform@cisco.com](mailto:datalearningplatform@cisco.com)

1)	After logging on DLP, click on Development Hub on the left column.<br>
2)	Select the pre-defined work space named as <b>wksp-scala</b>.<br>
3)	Click on the <b>Launch</b> button to open IDE workspace.<br>

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/selectionWorkSpace.PNG?raw=true)

## Step 2: Explore IDE Workspace

1)	Below two sections will help to explore the IDE for Word Count project(wordcount). In the IDE, files are listed in Left Panel.
Double click on WordCount.scala file. Left Panel will be populated with the code of this file. 

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/WordCountScalafile.PNG?raw=true)


<b>Pre-loaded raw data file named(wordcountinputfile1.txt) in HDFS environment.</b><br>
This program will count the number of words in the file by identifying spaces between words. This file is already pre-loaded in hadoop environment.

```
//Import libraries which are needed to run the program. 
import org.apache.spark.{SparkContext, SparkConf}
object WordCount
{
  def main(args: Array[String]) {
    val inputFile = args(0)
    val outputFile = args(1)
    val conf = new SparkConf().setAppName("wordCount")
    // Create a Scala Spark Context.
    val sc = new SparkContext(conf)
    // Load our input data.
    val input = sc.textFile(inputFile)
    // Split up into words.
    val words = input.flatMap(line => line.split(" "))
    // Transform into word and count.
    val counts = words.map(word => (word, 1)).reduceByKey{_ + _}
    // Save the word count back out to a text file, causing evaluation.
    counts.saveAsTextFile(outputFile)
  }
}
```
N.B: Use WordCount.scala to view the above code. 

# Step 3 :  Run the Program

1) Select the WordCountRun.sh file from left panel of the IDE and double click on it. 
![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/Step7.PNG?raw=true)

There are two parameters. 
a) Input Parameter: Here input file from hdfs path is "wordcountinputfile1.txt"
b) Output Parameter: Here output file which would be saved in hdfs.
   Input file: hdfs://172.16.1.11:8020/tmp/spark/input/wordcountinputfile1.txt.
   N.B: This is pre-loaded input file.
   Output file: hdfs://172.16.1.11:8020/tmp/spark/output/output10121
   <b>Change the output file name(e.g: <b>output47</b>) based on your choice.</b>
   

2) Double click on WordCound.scala file again. Change <b>package</b> as described in the below image and click on the "run" blue button. This process will build and package the program.
![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/buildWordCount.PNG?raw=true)

3) This will build the package. You can find the below screen shot if build process finished successfully.
![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/buildSuccessWordCount.PNG?raw=true)

4) If the build process finished successfully, then select "run" as described in the below image and click on blue run button. 
![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/runWordCount.PNG?raw=true)

5) Successful ran process will show the output as below. (There should not be any Exception if ran process finished successfully.)
![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/successRunProcess.PNG?raw=true)

5) After successful ran process, select "view" as shown the below screen and click on blue button. It will display the word count as below.
![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/FinalWordCount.PNG?raw=true)
Count of occurance of every word is showing and the process happen in HDFS loaded file,


An Example:
Input file has the text: <b>welcome to data data learning platform cisco</b>


Things to Try:

* Try with numeric data type
* Try with case sensitive data as well.

Completing this coding exercise, we have learned how to count the number of words in an input file using Spark Batch Processing. <br>

There are some more examples and exercise are available in the below mentioned link. This is for your reference.
[http://spark.apache.org/docs/latest/programming-guide.html](http://spark.apache.org/docs/latest/programming-guide.html).
